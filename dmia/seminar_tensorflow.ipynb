{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going deeper with Tensorflow\n",
    "\n",
    "In this seminar, we're going to play with [Tensorflow](https://www.tensorflow.org/) and see how it helps us build deep learning models.\n",
    "\n",
    "If you're running this notebook outside the course environment, you'll need to install tensorflow:\n",
    "* `pip install tensorflow` should install cpu-only TF on Linux & Mac OS\n",
    "* If you want GPU support from offset, see [TF install page](https://www.tensorflow.org/install/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.1)\n",
    "s = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warming up\n",
    "For starters, let's implement a python function that computes the sum of squares of numbers from 0 to N-1.\n",
    "* Use numpy or python\n",
    "* An array of numbers 0 to N - numpy.arange(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def sum_squares(N):\n",
    "    return np.cumsum(np.arange(0,N)**2)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 648 ms, sys: 264 ms, total: 912 ms\nWall time: 913 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "662921401752298880"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sum_squares(10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensoflow teaser\n",
    "\n",
    "Doing the very same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I gonna be your function parameter\n",
    "N = tf.placeholder('int64', name=\"input_to_your_function\")\n",
    "\n",
    "#i am a recipe on how to produce sum of squares of arange of N given N\n",
    "result = tf.reduce_sum((tf.range(N)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662921401752298880\nCPU times: user 572 ms, sys: 104 ms, total: 676 ms\nWall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#example of computing the same as sum_squares\n",
    "print(result.eval({N:10**8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does it work?\n",
    "1. define placeholders where you'll send inputs;\n",
    "2. make symbolic graph: a recipe for mathematical transformation of those placeholders;\n",
    "3. compute outputs of your graph with particular values for each placeholder\n",
    "  * output.eval({placeholder:value}) \n",
    "  * s.run(output, {placeholder:value})\n",
    "\n",
    "* So far there are two main entities: \"placeholder\" and \"transformation\"\n",
    "* Both can be numbers, vectors, matrices, tensors, etc.\n",
    "* Both can be int32/64, floats of booleans (uint8) of various size.\n",
    "\n",
    "* You can define new transformations as an arbitrary operation on placeholders and other transformations\n",
    " * tf.reduce_sum(tf.arange(N)\\**2) are 3 sequential transformations of placeholder N\n",
    " * There's a tensorflow symbolic version for every numpy function\n",
    "   * `a+b, a/b, a**b, ...` behave just like in numpy\n",
    "   * np.mean -> tf.reduce_mean\n",
    "   * np.arange -> tf.range\n",
    "   * np.cumsum -> tf.cumsum\n",
    "   * If if you can't find the op you need, see the [docs](https://www.tensorflow.org/api_docs/python).\n",
    " \n",
    " \n",
    "Still confused? We gonna fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Default placeholder that can be arbitrary float32 scalar, vertor, matrix, etc.\n",
    "arbitrary_input = tf.placeholder('float32')\n",
    "\n",
    "#Input vector of arbitrary length\n",
    "input_vector = tf.placeholder('float32',shape=(None,))\n",
    "\n",
    "#Input vector that _must_ have 10 elements and integer type\n",
    "fixed_vector = tf.placeholder('int32',shape=(10,))\n",
    "\n",
    "#Matrix of arbitrary n_rows and 15 columns (e.g. a minibatch your data table)\n",
    "input_matrix = tf.placeholder('float32',shape=(None,15))\n",
    "\n",
    "#You can generally use None whenever you don't need a specific shape\n",
    "input1 = tf.placeholder('float64',shape=(None,100,None))\n",
    "input2 = tf.placeholder('int32',shape=(None,None,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#elementwise multiplication\n",
    "double_the_vector = input_vector*2\n",
    "\n",
    "#elementwise cosine\n",
    "elementwise_cosine = tf.cos(input_vector)\n",
    "\n",
    "#difference between squared vector and vector itself\n",
    "vector_squares = input_vector**2 - input_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Practice time: create two vectors of type float32\n",
    "my_vector = tf.placeholder('float32',shape=(None,))\n",
    "my_vector2 = tf.placeholder('float32',shape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a transformation(recipe):\n",
    "#(vec1)*(vec2) / (sin(vec1) +1)\n",
    "my_transformation = my_vector*my_vector2/(tf.sin(my_vector) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"truediv:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(my_transformation)\n",
    "#it's okay, it's a symbolic graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.62913239,  2.09501147,  2.62899613,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "dummy = np.arange(5).astype('float32')\n",
    "\n",
    "my_transformation.eval({my_vector:dummy,my_vector2:dummy[::-1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing graphs\n",
    "\n",
    "It's often useful to visualize the computation graph when debugging or optimizing. \n",
    "Interactive visualization is where tensorflow really shines as compared to other frameworks. \n",
    "\n",
    "There's a special instrument for that, called Tensorboard. You can launch it from console:\n",
    "\n",
    "```tensorboard --logdir=/tmp/tboard --port=7007```\n",
    "\n",
    "If you're pathologically afraid of consoles, try this:\n",
    "\n",
    "```os.system(\"tensorboard --logdir=/tmp/tboard --port=7007 &\"```\n",
    "\n",
    "_(but don't tell anyone we taught you that)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port: 7000\n"
     ]
    }
   ],
   "source": [
    "# launch tensorflow the ugly way, uncomment if you need that\n",
    "import os\n",
    "port = 6000 + os.getuid()\n",
    "print(\"Port: %d\" % port)\n",
    "#!killall tensorboard\n",
    "os.system(\"tensorboard --logdir=./tboard --port=%d &\" % port)\n",
    "\n",
    "# show graph to tensorboard\n",
    "writer = tf.summary.FileWriter(\"./tboard\", graph=tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One basic functionality of tensorboard is drawing graphs. One you've run the cell above, go to `localhost:7007` in your browser and switch to _graphs_ tab in the topbar. \n",
    "\n",
    "Here's what you should see:\n",
    "\n",
    "<img src=\"https://s12.postimg.org/a374bmffx/tensorboard.png\" width=480>\n",
    "\n",
    "Tensorboard also allows you to draw graphs (e.g. learning curves), record images & audio ~~and play flash games~~. This is useful when monitoring learning progress and catching some training issues.\n",
    "\n",
    "One researcher said:\n",
    "```\n",
    "If you spent last four hours of your worktime watching as your algorithm prints numbers and draws figures, you're probably doing deep learning wrong.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read more on tensorboard usage [here](https://www.tensorflow.org/get_started/graph_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do It Yourself\n",
    "\n",
    "__[2 points max]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quest #1 - implement a function that computes a mean squared error of two input vectors\n",
    "# Your function has to take 2 vectors and return a single number\n",
    "\n",
    "v1 = tf.placeholder('float32',shape=(None,))\n",
    "v2 = tf.placeholder('float32',shape=(None,))\n",
    "\n",
    "mse = tf.reduce_mean((v1-v2)**2)\n",
    "\n",
    "compute_mse = lambda vector1, vector2: mse.eval({v1:vector1, v2:vector2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for n in [1,5,10,10**3]:\n",
    "    \n",
    "    elems = [np.arange(n),np.arange(n,0,-1), np.zeros(n),\n",
    "             np.ones(n),np.random.random(n),np.random.randint(100,size=n)]\n",
    "    \n",
    "    for el in elems:\n",
    "        for el_2 in elems:\n",
    "            true_mse = np.array(mean_squared_error(el,el_2))\n",
    "            my_mse = compute_mse(el,el_2)\n",
    "            if not np.allclose(true_mse,my_mse):\n",
    "                print('Wrong result:')\n",
    "                print('mse(%s,%s)' % (el,el_2))\n",
    "                print(\"should be: %f, but your function returned %f\" % (true_mse,my_mse))\n",
    "                raise ValueError(\"Что-то не так\")\n",
    "\n",
    "print(\"All tests passed\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables\n",
    "\n",
    "The inputs and transformations have no value outside function call. This isn't too comfortable if you want your model to have parameters (e.g. network weights) that are always present, but can change their value over time.\n",
    "\n",
    "Tensorflow solves this with `tf.Variable` objects.\n",
    "* You can assign variable a value at any time in your graph\n",
    "* Unlike placeholders, there's no need to explicitly pass values to variables when `s.run(...)`-ing\n",
    "* You can use variables the same way you use transformations \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating shared variable\n",
    "shared_vector_1 = tf.Variable(initial_value=np.ones(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial value [ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#initialize variable(s) with initial values\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "#evaluating shared variable (outside symbolicd graph)\n",
    "print(\"initial value\", s.run(shared_vector_1))\n",
    "\n",
    "# within symbolic graph you use them just as any other inout or transformation, not \"get value\" needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new value [ 0.  1.  2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "#setting new value\n",
    "s.run(shared_vector_1.assign(np.arange(5)))\n",
    "\n",
    "#getting that new value\n",
    "print(\"new value\", s.run(shared_vector_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.gradients - why graphs matter\n",
    "* Tensorflow can compute derivatives and gradients automatically using the computation graph\n",
    "* Gradients are computed as a product of elementary derivatives via chain rule:\n",
    "\n",
    "$$ {\\partial f(g(x)) \\over \\partial x} = {\\partial f(g(x)) \\over \\partial g(x)}\\cdot {\\partial g(x) \\over \\partial x} $$\n",
    "\n",
    "It can get you the derivative of any graph as long as it knows how to differentiate elementary operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_scalar = tf.placeholder('float32')\n",
    "\n",
    "scalar_squared = my_scalar**2\n",
    "\n",
    "#a derivative of scalar_squared by my_scalar\n",
    "derivative = tf.gradients(scalar_squared, my_scalar)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97ce884b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(-3,3)\n",
    "x_squared, x_squared_der = s.run([scalar_squared,derivative],\n",
    "                                 {my_scalar:x})\n",
    "\n",
    "plt.plot(x, x_squared,label=\"x^2\")\n",
    "plt.plot(x, x_squared_der, label=\"derivative\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why that rocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_vector = tf.placeholder('float32',[None])\n",
    "\n",
    "#Compute the gradient of the next weird function over my_scalar and my_vector\n",
    "#warning! Trying to understand the meaning of that function may result in permanent brain damage\n",
    "\n",
    "weird_psychotic_function = tf.reduce_mean((my_vector+my_scalar)**(1+tf.nn.moments(my_vector,[0])[1]) + 1./ tf.atan(my_scalar))/(my_scalar**2 + 1) + 0.01*tf.sin(2*my_scalar**1.5)*(tf.reduce_sum(my_vector)* my_scalar**2)*tf.exp((my_scalar-4)**2)/(1+tf.exp((my_scalar-4)**2))*(1.-(tf.exp(-(my_scalar-4)**2))/(1+tf.exp(-(my_scalar-4)**2)))**2\n",
    "\n",
    "der_by_scalar = tf.gradients(weird_psychotic_function, my_scalar)\n",
    "der_by_vector = tf.gradients(weird_psychotic_function, my_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting your derivative\n",
    "scalar_space = np.linspace(1, 7, 100)\n",
    "\n",
    "y = [s.run(weird_psychotic_function, {my_scalar:x, my_vector:[1, 2, 3]})\n",
    "     for x in scalar_space]\n",
    "\n",
    "plt.plot(scalar_space, y, label='function')\n",
    "\n",
    "y_der_by_scalar = [s.run(der_by_scalar, {my_scalar:x, my_vector:[1, 2, 3]})\n",
    "     for x in scalar_space]\n",
    "\n",
    "plt.plot(scalar_space, y_der_by_scalar, label='derivative')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost done - optimizers\n",
    "\n",
    "While you can perform gradient descent by hand with automatic grads from above, tensorflow also has some optimization methods implemented for you. Recall momentum & rmsprop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_guess = tf.Variable(np.zeros(2,dtype='float32'))\n",
    "y_true = tf.range(1,3,dtype='float32')\n",
    "\n",
    "loss = tf.reduce_mean((y_guess - y_true + tf.random_normal([2]))**2) \n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(0.01,0.9).minimize(loss,var_list=y_guess)\n",
    "\n",
    "#same, but more detailed:\n",
    "#updates = [[tf.gradients(loss,y_guess)[0], y_guess]]\n",
    "#optimizer = tf.train.MomentumOptimizer(0.01,0.9).apply_gradients(updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "guesses = [s.run(y_guess)]\n",
    "\n",
    "for _ in range(100):\n",
    "    s.run(optimizer)\n",
    "    guesses.append(s.run(y_guess))\n",
    "    \n",
    "    clear_output(True)\n",
    "    # plt.plot(*zip(*guesses),marker='.')\n",
    "    # plt.scatter(*s.run(y_true),c='red')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression example\n",
    "Implement the regular logistic regression training algorithm\n",
    "\n",
    "Tips:\n",
    "* Use a shared variable for weights\n",
    "* X and y are potential inputs\n",
    "* Compile 2 functions:\n",
    " * `train_function(X, y)` - returns error and computes weights' new values __(through updates)__\n",
    " * `predict_fun(X)` - just computes probabilities (\"y\") given data\n",
    " \n",
    " \n",
    "We shall train on a two-class MNIST dataset\n",
    "* please note that target `y` are `{0,1}` and not `{-1,1}` as in some formulae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y [shape - (360,)]: [0 1 0 1 0 1 0 0 1 1]\nX [shape - (360, 64)]:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits(2)\n",
    "\n",
    "X,y = mnist.data, mnist.target\n",
    "\n",
    "print(\"y [shape - %s]:\" % (str(y.shape)), y[:10])\n",
    "print(\"X [shape - %s]:\" % (str(X.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n [[  0.   0.   5.  13.   9.   1.   0.   0.   0.   0.]\n [  0.   0.   0.  12.  13.   5.   0.   0.   0.   0.]\n [  0.   0.   1.   9.  15.  11.   0.   0.   0.   0.]]\ny:\n [0 1 0 1 0 1 0 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9786f1e080>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9l/q9J/njqg1MAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97877c03c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('X:\\n',X[:3,:10])\n",
    "print('y:\\n',y[:10])\n",
    "plt.imshow(X[0].reshape([8,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "weights = tf.Variable(tf.truncated_normal([len(X[0]), 1]))\n",
    "# biases = tf.Variable(tf.zeros([1, 1]))\n",
    "input_X = tf.placeholder(tf.float32, shape=(None, len(X[0])))  # initial_values \n",
    "input_y = tf.placeholder(tf.float32, shape=(None, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y = tf.sigmoid(tf.matmul(input_X, weights)) # + biases)\n",
    "# <logistic loss (scalar, mean over sample)>\n",
    "loss = tf.reduce_mean(1 + tf.exp(-(2*input_y-1)*predicted_y))  \n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss, var_list=(weights))  #, biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <compile function that takes X and computes probabilities of y>\n",
    "predict_function = tf.sigmoid(tf.matmul(input_X, weights))  # + biases)\n",
    "predict_function_bin = lambda x: 1*(predict_function.eval({input_X:x}) > 0.5)\n",
    "# train_function = lambda s, dct: s.run([optimizer, loss], feed_dict=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "y_train = y_train.reshape((len(y_train), 1))\n",
    "y_test = y_test.reshape((len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 0:2.0000\ntest auc: 0.5\ntest auc: 0.5\nloss at iter 1:2.0000\ntest auc: 0.5\ntest auc: 0.5\nloss at iter 2:2.0000\ntest auc: 0.5\ntest auc: 0.5\nloss at iter 3:2.0000\ntest auc: 0.5\ntest auc: 0.5\nloss at iter 4:2.0000\ntest auc: 0.5\ntest auc: 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAD8CAYAAADwpviIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97869566a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "batch_size = 100\n",
    "n_batches = int(len(y_train)/batch_size)\n",
    "with tf.Session() as s:\n",
    "    s.run(init)\n",
    "    for i in range(5):  \n",
    "        # for step in range(n_batches):\n",
    "        # offset = (step * batch_size) % (len(y_train) - batch_size)\n",
    "        # batch_data = X_train[offset:(offset + batch_size), :]\n",
    "        # batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "        batch_data = X_train\n",
    "        batch_labels = y_train\n",
    "        # <run optimizer operation>\n",
    "        data_dict = {input_X:batch_data, input_y:batch_labels}\n",
    "        _, loss_i = s.run([optimizer, loss], feed_dict=data_dict)\n",
    "        \n",
    "        print(\"loss at iter %i:%.4f\" % (i, loss_i))\n",
    "        print(\"test auc:\", roc_auc_score(y_train, predict_function_bin(X_train)))\n",
    "        print(\"test auc:\", roc_auc_score(y_test, predict_function_bin(X_test)))\n",
    "        \n",
    "    # print (\"resulting weights:\")\n",
    "    # what are \"shared_weights\"? you have only asked to define \"weights\"\n",
    "    # plt.imshow(shared_weights.get_value().reshape(8, -1))\n",
    "    plt.imshow(weights.eval().reshape(8, -1))\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: my1stNN\n",
    "Your ultimate task for this week is to build your first neural network [almost] from scratch and pure tensorflow.\n",
    "\n",
    "This time you will same digit recognition problem, but at a larger scale\n",
    "* images are now 28x28\n",
    "* 10 different digits\n",
    "* 50k samples\n",
    "\n",
    "Note that you are not required to build 152-layer monsters here. A 2-layer (one hidden, one output) NN should already have ive you an edge over logistic regression.\n",
    "\n",
    "__[bonus score]__\n",
    "If you've already beaten logistic regression with a two-layer net, but enthusiasm still ain't gone, you can try improving the test accuracy even further! The milestones would be 95%/97.5%/98.5% accuraсy on test set.\n",
    "\n",
    "__SPOILER!__\n",
    "At the end of the notebook you will find a few tips and frequently made mistakes. If you feel enough might to shoot yourself in the foot without external assistance, we encourage you to do so, but if you encounter any unsurpassable issues, please do look there before mailing us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n(50000, 784)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/maria/Dropbox/edu/dmia/nn')\n",
    "from mnist import load_dataset\n",
    "\n",
    "#[down]loading the original MNIST dataset.\n",
    "#Please note that you should only train your NN on _train sample,\n",
    "# _val can be used to evaluate out-of-sample error, compare models or perform early-stopping\n",
    "# _test should be hidden under a rock untill final evaluation... But we both know it is near impossible to catch you evaluating on it.\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_dataset()\n",
    "\n",
    "print (X_train.shape,y_train.shape)\n",
    "img_size = np.shape(X_train[0])[0]\n",
    "X_train = X_train.reshape((len(X_train), img_size*img_size))\n",
    "X_val = X_val.reshape((len(X_val), img_size*img_size))\n",
    "X_test = X_test.reshape((len(X_test), img_size*img_size))\n",
    "y_train = np.array([[1 if ytr == i else 0 for i in range(10)] for ytr in y_train])\n",
    "y_val = np.array([[1 if ytr == i else 0 for i in range(10)] for ytr in y_val])\n",
    "y_test = np.array([[1 if ytr == i else 0 for i in range(10)] for ytr in y_test])\n",
    "print (X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9786892978>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97869b2860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_sizes = [500, 20]\n",
    "nonlin = [tf.nn.sigmoid, tf.nn.relu]\n",
    "graph = tf.Graph()\n",
    "train_X = tf.placeholder(tf.float32, shape=(None, img_size * img_size))\n",
    "train_y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "# #   \n",
    "weights = [tf.Variable(tf.truncated_normal([img_size * img_size, hidden_sizes[0]]))]\n",
    "biases = [tf.Variable(tf.zeros([hidden_sizes[0]]))]\n",
    "for i in range(len(hidden_sizes)-1):\n",
    "    weights.append(tf.Variable(tf.truncated_normal([hidden_sizes[i], hidden_sizes[i+1]])))\n",
    "    biases.append(tf.Variable(tf.zeros([hidden_sizes[i+1]])))\n",
    "weights.append(tf.Variable(tf.truncated_normal([hidden_sizes[-1], 10])))\n",
    "biases.append(tf.Variable(tf.zeros([10])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prop(x, w, b, nonlin):\n",
    "    h = tf.matmul(x, w[0]) + b[0]\n",
    "    for i in range(len(nonlin)):\n",
    "        h = nonlin[i](h)\n",
    "        h = tf.matmul(h, w[i+1]) + b[i+1]\n",
    "    return h\n",
    "\n",
    "# h = tf.matmul(tf.nn.relu(tf.matmul(train_X, weights[0]) + biases[0]),  weights[1]) + biases[1]\n",
    "h = forward_prop(train_X, weights, biases, nonlin)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=train_y, logits=h)) \n",
    "      # + (tf.reduce_sum(weights[0]**2) + tf.reduce_sum(weights[1]**2))*0.001\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "# optimizer = tf.train.MomentumOptimizer(0.01,0.9).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "predict_y = lambda x: tf.nn.softmax(forward_prop(x, weights, biases))\n",
    "\n",
    "get_accuracy = lambda y, y_true: (np.sum(np.argmax(y_true, 1) == np.argmax(y, 1)) / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch training       loss, epoch 0  : 50.887\nMinibatch validation accuracy, epoch 0  : 0.115"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 1  : 0.784"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 1  : 0.793"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 2  : 0.258"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 2  : 0.912"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 3  : 0.161"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 3  : 0.937"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 4  : 0.097"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 4  : 0.950"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 5  : 0.088"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 5  : 0.955"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 6  : 0.131"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 6  : 0.958"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 7  : 0.049"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 7  : 0.958"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 8  : 0.117"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 8  : 0.960"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 9  : 0.046"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 9  : 0.962"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 10  : 0.047"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 10  : 0.959"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 11  : 0.042"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 11  : 0.958"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 12  : 0.073"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 12  : 0.962"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 13  : 0.006"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 13  : 0.965"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 14  : 0.043"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 14  : 0.960"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 15  : 0.009"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 15  : 0.968"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch training       loss, epoch 16  : 0.119"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nMinibatch validation accuracy, epoch 16  : 0.969"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 100\n",
    "n_batches = int(len(X_train)/batch_size)\n",
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i_epoch in range(n_epochs): # I don't know if that each epoch covers all data...\n",
    "        for i in range(500): # n_batches-1): #n_batches-1): \n",
    "            to_take = np.random.choice([j for j in range(len(X_train))], batch_size)\n",
    "            # X_batch_i = X_train[int(n_batches*i): n_batches * (i+1), :]\n",
    "            # y_batch_i = y_train[int(n_batches*i): n_batches * (i+1), :]\n",
    "            X_batch_i = X_train[to_take, :]\n",
    "            y_batch_i = y_train[to_take, :]\n",
    "            data_dict = {train_X: X_batch_i,\n",
    "                         train_y: y_batch_i}\n",
    "            _, loss_i = session.run([optimizer, loss], feed_dict=data_dict)\n",
    "            del data_dict\n",
    "            if (i%500) == 0:\n",
    "                print(\"Minibatch training       loss, epoch {0}  : {1:2.3f}\".format(i_epoch, loss_i))\n",
    "                # print(\"Minibatch validation accuracy, epoch {0}  : {1:2.3f}\".\n",
    "                #       format(i_epoch, get_accuracy(forward_prop(X_train, weights, biases, nonlin).eval(), y_train)))\n",
    "                print(\"Minibatch validation accuracy, epoch {0}  : {1:2.3f}\".\n",
    "                      format(i_epoch, get_accuracy(forward_prop(X_val, weights, biases, nonlin).eval(), y_val)))\n",
    "    print(\"Test accuracy: {0:2.3f}\".format(get_accuracy(forward_prop(X_test, weights, biases, nonlin).eval(), y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <predict & evaluate on test here, right? No cheating pls.>\n",
    "# I am going to improve the accuracy this Friday..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# SPOILERS!\n",
    "\n",
    "Recommended pipeline\n",
    "\n",
    "* Adapt logistic regression from previous assignment to classify some number against others (e.g. zero vs nonzero)\n",
    "* Generalize it to multiclass logistic regression.\n",
    "  - Either try to remember lecture 0 or google it.\n",
    "  - Instead of weight vector you'll have to use matrix (feature_id x class_id)\n",
    "  - softmax (exp over sum of exps) can implemented manually or as T.nnet.softmax (stable)\n",
    "  - probably better to use STOCHASTIC gradient descent (minibatch)\n",
    "    - in which case sample should probably be shuffled (or use random subsamples on each iteration)\n",
    "* Add a hidden layer. Now your logistic regression uses hidden neurons instead of inputs.\n",
    "  - Hidden layer uses the same math as output layer (ex-logistic regression), but uses some nonlinearity (sigmoid) instead of softmax\n",
    "  - You need to train both layers, not just output layer :)\n",
    "  - Do not initialize layers with zeros (due to symmetry effects). A gaussian noize with small sigma will do.\n",
    "  - 50 hidden neurons and a sigmoid nonlinearity will do for a start. Many ways to improve. \n",
    "  - In ideal casae this totals to 2 .dot's, 1 softmax and 1 sigmoid\n",
    "  - __make sure this neural network works better than logistic regression__\n",
    "  \n",
    "* Now's the time to try improving the network. Consider layers (size, neuron count),  nonlinearities, optimization methods, initialization - whatever you want, but please avoid convolutions for now."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
